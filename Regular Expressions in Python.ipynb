{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First day!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie='fox and kelley soon become bitter rivals because the new fox books store is opening up right across the block from the small business .'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of characters in this review: 135\n"
     ]
    }
   ],
   "source": [
    "# Find characters in movie variable\n",
    "length_string = len(movie)\n",
    "\n",
    "# Convert to string\n",
    "to_string = str(length_string)\n",
    "\n",
    "# Predefined variable\n",
    "statement = \"Number of characters in this review:\"\n",
    "\n",
    "# Concatenate strings and print result\n",
    "print(statement+' '+to_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie1='the most significant tension of _election_ is the potential relationship between a teacher and his student .'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie2='the most significant tension of _rushmore_ is the potential relationship between a teacher and his student .'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the most significant tension of _rushmore_ is the potential relationship between a teacher and his student .\n",
      "the most significant tension of _rushmore_ is the potential relationship between a teacher and his student .\n"
     ]
    }
   ],
   "source": [
    "# Select the first 32 characters of movie1\n",
    "first_part = movie1[:32]\n",
    "\n",
    "# Select from 43rd character to the end of movie1\n",
    "last_part = movie1[42:]\n",
    "\n",
    "# Select from 33rd to the 42nd character\n",
    "middle_part = movie2[32:42]\n",
    "\n",
    "# Print concatenation and movie2 variable\n",
    "print(first_part+middle_part+last_part) \n",
    "print(movie2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Palindromes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie='oh my God! desserts I stressed was an ugly movie'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desserts I stressed\n"
     ]
    }
   ],
   "source": [
    "# Get the word\n",
    "movie_title = movie[11:30]\n",
    "\n",
    "# Obtain the palindrome\n",
    "palindrome = movie_title[::-1]\n",
    "\n",
    "# Print the word if it's a palindrome\n",
    "if movie_title == palindrome:\n",
    "\tprint(movie_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie= '$I supposed that coming from MTV Films I should expect no less$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$i supposed that coming from mtv films i should expect no less$\n",
      "i supposed that coming from mtv films i should expect no less\n",
      "['i', 'supposed', 'that', 'coming', 'from', 'mtv', 'films', 'i', 'should', 'expect', 'no', 'less']\n",
      "p\n"
     ]
    }
   ],
   "source": [
    "# Convert to lowercase and print the result\n",
    "movie_lower = movie.lower()\n",
    "print(movie_lower)\n",
    "\n",
    "# Remove whitespaces and print the result\n",
    "movie_no_space = movie_lower.strip(\"$\")\n",
    "print(movie_no_space)\n",
    "\n",
    "# Split the string into substrings and print the result\n",
    "movie_split = movie_no_space.split()\n",
    "print(movie_split)\n",
    "\n",
    "# Select root word and print the result\n",
    "word_root = movie_split[1][2]\n",
    "print(word_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time to join!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie='the film,however,is all good<\\\\i>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the film,however,is all good\n",
      "['the film', 'however', 'is all good']\n",
      "the film however is all good\n"
     ]
    }
   ],
   "source": [
    "# Remove tags happening at the end and print results\n",
    "movie_tag = movie.rstrip(\"<\\i>\")\n",
    "print(movie_tag)\n",
    "\n",
    "# Split the string using commas and print results\n",
    "movie_no_comma = movie_tag.split(\",\")\n",
    "print(movie_no_comma)\n",
    "\n",
    "# Join back together and print results\n",
    "movie_join = ' '.join(movie_no_comma)\n",
    "print(movie_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split lines or split the line?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "file='mtv films election, a high school comedy, is a current example\\nfrom there, director steven spielberg wastes no time, taking us into the water on a midnight swim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mtv films election, a high school comedy, is a current example', 'from there, director steven spielberg wastes no time, taking us into the water on a midnight swim']\n",
      "['mtv films election', ' a high school comedy', ' is a current example']\n",
      "['from there', ' director steven spielberg wastes no time', ' taking us into the water on a midnight swim']\n"
     ]
    }
   ],
   "source": [
    "# Split string at line boundaries\n",
    "file_split = file.splitlines()\n",
    "\n",
    "# Print file_split\n",
    "print(file_split)\n",
    "\n",
    "# Complete for-loop to split by commas\n",
    "for substring in file_split:\n",
    "    substring_split = substring.split(\",\")\n",
    "    print(substring_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calling by its name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "courses=['artificial intelligence', 'neural networks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you are interested in artificial intelligence, you can take the course related to neural networks\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary\n",
    "plan = {\n",
    "  \t\t\"field\": courses[0],\n",
    "        \"tool\": courses[1]\n",
    "        }\n",
    "\n",
    "# Define string with placeholders\n",
    "my_message = \"If you are interested in {plan[field]}, you can take the course related to {plan[tool]}\"\n",
    "\n",
    "# Use dictionary to replace placehoders\n",
    "print(my_message.format(plan=plan))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What day is today?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good morning. Today is June 29, 2019. It's 08:00 ... time to work!\n"
     ]
    }
   ],
   "source": [
    "# Import datetime \n",
    "from datetime import datetime\n",
    "\n",
    "# Assign date to get_date\n",
    "get_date = datetime.now()\n",
    "\n",
    "# Add named placeholders with format specifiers\n",
    "message = \"Good morning. Today is {today:%B %d, %Y}. It's {today:%H:%M} ... time to work!\"\n",
    "\n",
    "# Format date\n",
    "print(message.format(today=get_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Literally formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "field1='sexiest job'\n",
    "fact1=21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data science is considered 'sexiest job' in the 21st century\n"
     ]
    }
   ],
   "source": [
    "# Complete the f-string\n",
    "print(f\"Data science is considered {field1!r} in the {fact1:d}st century\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact2=25000\n",
    "00000000000000\n",
    "field2='data is produced daily'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About 2.500000e+04 of data is produced daily in the world\n"
     ]
    }
   ],
   "source": [
    "# Complete the f-string\n",
    "print(f\"About {fact2:e} of {field2} in the world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "field3='Individuals'\n",
    "fact3=72.41415415151\n",
    "fact4=1.09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individuals create around 72.41% of the data but only 1.1% is analyzed\n"
     ]
    }
   ],
   "source": [
    "# Complete the f-string\n",
    "print(f\"{field3} create around {fact3:.2f}% of the data but only {fact4:.1f}% is analyzed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "number1=120\n",
    "number2=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 tweets were downloaded in 7 minutes indicating a speed of 17.1 tweets per min\n"
     ]
    }
   ],
   "source": [
    "# Include both variables and the result of dividing them \n",
    "print(f\"{number1} tweets were downloaded in {number2} minutes indicating a speed of {number1/number2:.1f} tweets per min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "www.datacamp.com\n"
     ]
    }
   ],
   "source": [
    "string1='httpswww.datacamp.com'\n",
    "# Replace the substring http by an empty string\n",
    "print(f\"{string1.replace('https', '')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only 5.83% of the posts contain links\n"
     ]
    }
   ],
   "source": [
    "list_links=['www.news.com',\n",
    " 'www.google.com',\n",
    " 'www.yahoo.com',\n",
    " 'www.bbc.com',\n",
    " 'www.msn.com',\n",
    " 'www.facebook.com',\n",
    " 'www.news.google.com']\n",
    "# Divide the length of list by 120 rounded to two decimals\n",
    "print(f\"Only {(len(list_links)*100/120):.2f}% of the posts contain links\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The price for a house in the east neighborhood was $1232443 in 04-20-2007\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "east={'date': datetime.datetime(2007, 4, 20, 0, 0), 'price': 1232443}\n",
    "# Access values of date and price in east dictionary\n",
    "print(f\"The price for a house in the east neighborhood was ${east['price']} in {east['date']:%m-%d-%Y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The price for a house in the west neighborhood was $1432673 in 05-26-2006.\n"
     ]
    }
   ],
   "source": [
    "west={'date': datetime.datetime(2006, 5, 26, 0, 0), 'price': 1432673}\n",
    "# Access values of date and price in west dictionary\n",
    "print(f\"The price for a house in the west neighborhood was ${west['price']} in {west['date']:%m-%d-%Y}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing a report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "description1='suite of libraries and programs for symbolic and statistical natural language processing (NLP) for English written in the Python programming language. It was developed by Steven Bird and Edward Loper in the Department of Computer and Information Science at the University of Pennsylvania.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "description2= 'Python library for processing textual data. It provides a simple API for diving into common natural language processing tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool2='TextBlob'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool3='Gensim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "description3= 'Gensim is a robust open-source vector space modeling and topic modeling toolkit implemented in Python. It uses NumPy, SciPy and optionally Cython for performance. Gensim is specifically designed to handle large text collections, using data streaming and efficient incremental algorithms, which differentiates it from most other scientific software packages that only target batch and in-memory processing.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool1='Natural Language Toolkit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural Language Toolkit is a suite of libraries and programs for symbolic and statistical natural language processing (NLP) for English written in the Python programming language. It was developed by Steven Bird and Edward Loper in the Department of Computer and Information Science at the University of Pennsylvania.\n",
      "TextBlob is a Python library for processing textual data. It provides a simple API for diving into common natural language processing tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more.\n",
      "Gensim is a Gensim is a robust open-source vector space modeling and topic modeling toolkit implemented in Python. It uses NumPy, SciPy and optionally Cython for performance. Gensim is specifically designed to handle large text collections, using data streaming and efficient incremental algorithms, which differentiates it from most other scientific software packages that only target batch and in-memory processing.\n"
     ]
    }
   ],
   "source": [
    "# Import Template\n",
    "from string import Template\n",
    "\n",
    "# Create a template\n",
    "wikipedia = Template(\"$tool is a $description\")\n",
    "\n",
    "# Substitute variables in template\n",
    "print(wikipedia.substitute(tool=tool1, description=description1))\n",
    "print(wikipedia.substitute(tool=tool2, description=description2))\n",
    "print(wikipedia.substitute(tool=tool3, description=description3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are offering a 3-month beginner course on Natural Language Toolkit just for $ 20 monthly\n"
     ]
    }
   ],
   "source": [
    "tools=['Natural Language Toolkit', '20', 'month']\n",
    "# Import template\n",
    "from string import Template\n",
    "\n",
    "# Select variables\n",
    "our_tool = tools[0]\n",
    "our_fee = tools[1]\n",
    "our_pay = tools[2]\n",
    "\n",
    "# Create template\n",
    "course = Template(\"We are offering a 3-month beginner course on $tool just for $$ $fee ${pay}ly\")\n",
    "\n",
    "# Substitute identifiers with three variables\n",
    "print(course.substitute(tool=our_tool, fee=our_fee, pay=our_pay))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regular Expression for Pattern Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis='@robot9! @robot4& I have a good feeling that the show isgoing to be amazing! @robot9$ @robot7%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@robot9!', '@robot4&', '@robot9$', '@robot7%']\n"
     ]
    }
   ],
   "source": [
    "# Import the re module\n",
    "import re\n",
    "\n",
    "# Write the regex\n",
    "regex = r\"@robot\\d\\W\"\n",
    "\n",
    "# Find all matches of regex\n",
    "print(re.findall(regex, sentiment_analysis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis=\"Unfortunately one of those moments wasn't a giant squid monster. User_mentions:2, likes: 9, number of retweets: 7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['User_mentions:2']\n"
     ]
    }
   ],
   "source": [
    "# Write a regex to obtain user mentions\n",
    "print(re.findall(r\"User_mentions:\\d\", sentiment_analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['likes: 9']\n"
     ]
    }
   ],
   "source": [
    "# Write a regex to obtain number of likes\n",
    "print(re.findall(r\"likes:\\s\\d\",sentiment_analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['number of retweets: 7']\n"
     ]
    }
   ],
   "source": [
    "# Write a regex to obtain number of retweets\n",
    "print(re.findall(r\"number\\sof\\sretweets:\\s\\d\", sentiment_analysis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis= 'He#newHis%newTin love with$newPscrappy. #8break%He is&newYmissing him@newLalready'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He is in love with scrappy.  He is missing him already\n"
     ]
    }
   ],
   "source": [
    "# Write a regex to match pattern separating sentences\n",
    "regex_sentence = r\"\\W\\dbreak\\W\"\n",
    "\n",
    "# Replace the regex_sentence with a space\n",
    "sentiment_sub = re.sub(regex_sentence, \" \", sentiment_analysis)\n",
    "\n",
    "# Write a regex to match pattern separating words\n",
    "regex_words = r\"\\Wnew\\w\"\n",
    "\n",
    "# Replace the regex_words and print the result\n",
    "sentiment_final = re.sub(regex_words,' ',sentiment_sub)\n",
    "print(sentiment_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Everything clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "sentiment_analysis='Boredd. Colddd @blueKnight Internet keeps'\n",
    "# Import re module\n",
    "import re\n",
    "\n",
    "for tweet in sentiment_analysis:\n",
    "  \t# Write regex to match http links and print out result\n",
    "\tprint(re.findall(r\"http\\S+\", tweet))\n",
    "\n",
    "\t# Write regex to match user mentions and print out result\n",
    "\tprint(re.findall(r\"@\\w+\", tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Some time ago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "date='27 minutes ago'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['27 minutes ago']\n"
     ]
    }
   ],
   "source": [
    "# Complete the for loop with a regex to find dates\n",
    "print(re.findall(r\"\\d{1,2}\\s\\w+\\s\\w+\", date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['23rd june 2018']\n"
     ]
    }
   ],
   "source": [
    "date='23rd june 2018'\n",
    "print(re.findall(r\"\\d{1,2}\\w+\\s\\w+\\s\\d{4}\", date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1st september 2019 17:25']\n"
     ]
    }
   ],
   "source": [
    "date='1st september 2019 17:25'\n",
    "print(re.findall(r\"\\d{1,2}\\w+\\s\\w+\\s\\d{4}\\s\\d{1,2}:\\d{2}\", date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis='ITS NOT ENOUGH TO SAY THAT IMISS U #MissYou #SoMuch #Friendship #Forever'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ITS', 'NOT', 'ENOUGH', 'TO', 'SAY', 'THAT', 'IMISS', 'U', '']\n"
     ]
    }
   ],
   "source": [
    "# Write a regex matching the hashtag pattern\n",
    "regex = r\"#\\w+\"\n",
    "\n",
    "# Replace the regex by an empty string\n",
    "no_hashtag = re.sub(regex, \"\", sentiment_analysis)\n",
    "\n",
    "# Get tokens by splitting text\n",
    "print(re.split(r\"\\s+\", no_hashtag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Give me your email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails= ['n.john.smith@gmail.com', '87victory@hotmail.com', '!#mary-=@msca.net']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The email n.john.smith@gmail.com is a valid email\n",
      "The email 87victory@hotmail.com is a valid email\n",
      "The email !#mary-=@msca.net is invalid\n"
     ]
    }
   ],
   "source": [
    "# Write a regex to match a valid email address\n",
    "regex = r\"[A-Za-z0-9!#%&*\\$\\.]+@\\w+\\.com\"\n",
    "\n",
    "for example in emails:\n",
    "  \t# Match the regex to the string\n",
    "    if re.match(regex, example):\n",
    "        # Complete the format method to print out the result\n",
    "      \tprint(\"The email {email_example} is a valid email\".format(email_example=example))\n",
    "    else:\n",
    "      \tprint(\"The email {email_example} is invalid\".format(email_example=example))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invalid Passwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The password Apple34!rose is a valid password\n",
      "The password My87hou#4$ is a valid password\n",
      "The password abc123 is invalid\n"
     ]
    }
   ],
   "source": [
    "passwords=['Apple34!rose', 'My87hou#4$', 'abc123']\n",
    "# Write a regex to match a valid password\n",
    "regex = r\"[A-Za-z0-9!#%&*\\$\\.]{8,20}\" \n",
    "\n",
    "for example in passwords:\n",
    "  \t# Scan the strings to find a match\n",
    "    if re.search(regex, example):\n",
    "        # Complete the format method to print out the result\n",
    "      \tprint(\"The password {pass_example} is a valid password\".format(pass_example=example))\n",
    "    else:\n",
    "      \tprint(\"The password {pass_example} is invalid\".format(pass_example=example))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to see that amazing show again!\n"
     ]
    }
   ],
   "source": [
    "string='I want to see that <strong>amazing show</strong> again!'\n",
    "# Import re\n",
    "import re\n",
    "\n",
    "# Write a regex to eliminate tags\n",
    "string_notags = re.sub(r\"<.+?>\", \"\", string)\n",
    "\n",
    "# Print out the result\n",
    "print(string_notags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greedy matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis='Was intending to finish editing my 536-page novel manuscript tonight, but that will probably not happen. And only 12 pages are left '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5', '3', '6', '1', '2']\n"
     ]
    }
   ],
   "source": [
    "# Write a lazy regex expression \n",
    "numbers_found_lazy = re.findall(r\"[0-9]+?\", sentiment_analysis)\n",
    "\n",
    "# Print out the result\n",
    "print(numbers_found_lazy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['536', '12']\n"
     ]
    }
   ],
   "source": [
    "# Write a greedy regex expression \n",
    "numbers_found_greedy = re.findall(r\"[0-9]+\", sentiment_analysis)\n",
    "\n",
    "# Print out the result\n",
    "print(numbers_found_greedy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lazy approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis=\"Put vacation photos online (They were so cute) a few yrs ago. PC crashed, and now I forget the name of the site (I'm crying). \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"(They were so cute) a few yrs ago. PC crashed, and now I forget the name of the site (I'm crying)\"]\n"
     ]
    }
   ],
   "source": [
    "# Write a greedy regex expression to match \n",
    "sentences_found_greedy = re.findall(r\"\\(.*\\)\", sentiment_analysis)\n",
    "\n",
    "# Print out the result\n",
    "print(sentences_found_greedy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(They were so cute)', \"(I'm crying)\"]\n"
     ]
    }
   ],
   "source": [
    "# Write a lazy regex expression\n",
    "sentences_found_lazy = re.findall(r\"\\(.*?\\)\", sentiment_analysis)\n",
    "\n",
    "# Print out the results\n",
    "print(sentences_found_lazy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advance Regular Expression concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=['Just got ur newsletter, those fares really are unbelievable. Write to statravelAU@gmail.com or statravelpo@hotmail.com. They have amazing prices',\n",
    " 'I should have paid more attention when we covered photoshop in my webpage design class in undergrad. Contact me Hollywoodheat34@msn.net.',\n",
    " 'hey missed ya at the meeting. Read your email! msdrama098@hotmail.com']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lists of users found in this tweet: ['statravelAU', 'statravelpo']\n",
      "Lists of users found in this tweet: ['Hollywoodheat34']\n",
      "Lists of users found in this tweet: ['msdrama098']\n"
     ]
    }
   ],
   "source": [
    "# Write a regex that matches email\n",
    "regex_email = r\"([A-Za-z0-9]+)@\\S+\"\n",
    "\n",
    "for tweet in A:\n",
    "    # Find all matches of regex in each tweet\n",
    "    email_matched = re.findall(regex_email, tweet)\n",
    "\n",
    "    # Complete the format method to print the results\n",
    "    print(\"Lists of users found in this tweet: {}\".format(email_matched))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight='Subject: You are now ready to fly. Here you have your boarding pass IB3723 AMS-MAD 06OCT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Airline: IB Flight number: 3723\n",
      "Departure: AMS Destination: MAD\n",
      "Date: 06OCT\n"
     ]
    }
   ],
   "source": [
    "# Import re\n",
    "import re\n",
    "\n",
    "# Write regex to capture information of the flight\n",
    "regex = r\"([A-Z]{2})(\\d{4})\\s([A-Z]{3})-([A-Z]{3})\\s(\\d{2}[A-Z]{3})\"\n",
    "\n",
    "# Find all matches of the flight information\n",
    "flight_matches = re.findall(regex, flight)\n",
    "    \n",
    "#Print the matches\n",
    "print(\"Airline: {} Flight number: {}\".format(flight_matches[0][0], flight_matches[0][1]))\n",
    "print(\"Departure: {} Destination: {}\".format(flight_matches[0][2], flight_matches[0][3]))\n",
    "print(\"Date: {}\".format(flight_matches[0][4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=['I totally love the concert The Book of Souls World Tour. It kinda amazing!',\n",
    " 'I enjoy the movie Wreck-It Ralph. I watched with my boyfriend.',\n",
    " \"I still like the movie Wish Upon a Star. Too bad Disney doesn't show it anymore.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive comments found [('love', 'concert', 'The Book of Souls World Tour')]\n",
      "Positive comments found [('enjoy', 'movie', 'Wreck-It Ralph')]\n",
      "Positive comments found [('like', 'movie', 'Wish Upon a Star')]\n"
     ]
    }
   ],
   "source": [
    "# Write a regex that matches sentences with the optional words\n",
    "regex_positive = r\"(love|like|enjoy).+?(movie|concert)\\s(.+?)\\.\"\n",
    "\n",
    "for tweet in s:\n",
    "\t# Find all matches of regex in tweet\n",
    "    positive_matches = re.findall(regex_positive, tweet)\n",
    "    \n",
    "    # Complete format to print out the results\n",
    "    print(\"Positive comments found {}\".format(positive_matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen=['That was horrible! I really dislike the movie The cabin and the ant. So boring.',\n",
    " \"I disapprove the movie Honest with you. It's full of cliches.\",\n",
    " 'I dislike very much the concert After twelve Tour. The sound was horrible.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative comments found [('dislike', 'The cabin and the ant')]\n",
      "Negative comments found [('disapprove', 'Honest with you')]\n",
      "Negative comments found [('dislike', 'After twelve Tour')]\n"
     ]
    }
   ],
   "source": [
    "# Write a regex that matches sentences with the optional words\n",
    "regex_negative = r\"(hate|dislike|disapprove).+?(?:movie|concert)\\s(.+?)\\.\"\n",
    "\n",
    "for tweet in sen:\n",
    "\t# Find all matches of regex in tweet\n",
    "    negative_matches = re.findall(regex_negative, tweet)\n",
    "    \n",
    "    # Complete format to print out the results\n",
    "    print(\"Negative comments found {}\".format(negative_matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "r='Provider will invoice Client for Services performed within 30 days of performance.  Client will pay Provider as set forth in each Statement of Work within 30 days of receipt and acceptance of such invoice. It is understood that payments to Provider for services rendered shall be made in full as agreed, without any deductions for taxes of any kind whatsoever, in conformity with Providerâ€™s status as an independent contractor. Signed on 03/25/2001.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our first contract is dated back to 2001. Particularly, the day 25 of the month 03.\n"
     ]
    }
   ],
   "source": [
    "# Write regex and scan contract to capture the dates described\n",
    "regex_dates = r\"Signed\\son\\s(\\d{2})/(\\d{2})/(\\d{4})\"\n",
    "dates = re.search(regex_dates, r)\n",
    "\n",
    "# Assign to each key the corresponding match\n",
    "signature = {\n",
    "\t\"day\": dates.group(2),\n",
    "\t\"month\": dates.group(1),\n",
    "\t\"year\": dates.group(3)\n",
    "}\n",
    "# Complete the format method to print-out\n",
    "print(\"Our first contract is dated back to {data[year]}. Particularly, the day {data[day]} of the month {data[month]}.\".format(data=signature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa=['@marykatherine_q i know! I heard it this morning and wondered the same thing. Moscooooooow is so behind the times',\n",
    " 'Staying at a friends house...neighborrrrrrrs are so loud-having a party',\n",
    " 'Just woke up an already have read some e-mail']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elongated word found: Moscooooooow\n",
      "Elongated word found: neighborrrrrrrs\n",
      "No elongated word found\n"
     ]
    }
   ],
   "source": [
    "# Complete the regex to match an elongated word\n",
    "regex_elongated = r\"\\w*(\\w)\\1\\w*\"\n",
    "\n",
    "for tweet in sa:\n",
    "\t# Find if there is a match in each tweet \n",
    "\tmatch_elongated = re.search(regex_elongated, tweet)\n",
    "    \n",
    "\tif match_elongated:\n",
    "\t\t# Assign the captured group zero \n",
    "\t\telongated_word = match_elongated.group(0)\n",
    "        \n",
    "\t\t# Complete the format method to print the word\n",
    "\t\tprint(\"Elongated word found: {word}\".format(word=elongated_word))\n",
    "\telse:\n",
    "\t\tprint(\"No elongated word found\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['excellent', 'Excellent']\n"
     ]
    }
   ],
   "source": [
    "sentiment_analysis='You need excellent python skills to be a data scientist. Must be! Excellent python'\n",
    "# Positive lookahead\n",
    "look_ahead = re.findall(r\"\\w+(?=\\spython)\", sentiment_analysis)\n",
    "\n",
    "# Print out\n",
    "print(look_ahead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['skills']\n"
     ]
    }
   ],
   "source": [
    "# Positive lookbehind\n",
    "look_behind = re.findall(r\"(?<=[Pp]ython\\s)\\w+\", sentiment_analysis)\n",
    "\n",
    "# Print out\n",
    "print(look_behind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "cellphones=['4564-646464-01', '345-5785-544245', '6476-579052-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4564-646464-01']\n",
      "[]\n",
      "['6476-579052-01']\n"
     ]
    }
   ],
   "source": [
    "for phone in cellphones:\n",
    "\t# Get all phone numbers not preceded by area code\n",
    "\tnumber = re.findall(r\"(?<!\\d{3}-)\\d{4}-\\d{6}-\\d{2}\", phone)\n",
    "\tprint(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['345-5785-544245']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for phone in cellphones:\n",
    "\t# Get all phone numbers not followed by optional extension\n",
    "\tnumber = re.findall(r\"\\d{3}-\\d{4}-\\d{6}(?!-\\d{2})\", phone)\n",
    "\tprint(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
